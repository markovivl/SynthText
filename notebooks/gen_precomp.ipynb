{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d71d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import argparse\n",
    "\n",
    "import scipy.io as sio\n",
    "import json\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from prep_scripts.floodFill import get_mask\n",
    "\n",
    "from prep_scripts.ucm import UCM, filter_ucm\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ebb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_IMPATHS = '../datasets/all_impaths.txt'\n",
    "\n",
    "PART_START = 0\n",
    "PART_END = 10\n",
    "\n",
    "SAVE_PATH = '../datasets'\n",
    "\n",
    "\n",
    "def normalize_depth(depth):\n",
    "    max_d = np.max(depth)\n",
    "    min_d = np.min(depth)\n",
    "    depth = (depth - np.min(depth))/(np.max(depth) - np.min(depth))\n",
    "    depth[depth < 0] = 0\n",
    "    depth[depth > 1] = 1\n",
    "    return depth\n",
    "\n",
    "def get_depth(img):\n",
    "    input_batch = transform(img).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_batch)\n",
    "        prediction = torch.nn.functional.interpolate(\n",
    "            prediction.unsqueeze(1),\n",
    "            size=img.shape[:2],\n",
    "            mode=\"bicubic\",\n",
    "            align_corners=False,\n",
    "        ).squeeze()\n",
    "\n",
    "    output = prediction.cpu().numpy()\n",
    "\n",
    "    new_depth = (1 - normalize_depth(output)) * 60\n",
    "    \n",
    "    return new_depth\n",
    "\n",
    "def clean_impath(name):\n",
    "    num, folder = name.split('/')[-1], name.split('/')[-2]\n",
    "    num = num.split('.')[0]\n",
    "    f_e = num.split('_')\n",
    "    new_name = f'ct_{f_e[-1]}'\n",
    "    return new_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef79e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/jovyan/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Large\")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform = midas_transforms.dpt_transform\n",
    "start = time.time()\n",
    "ucm_model = UCM()\n",
    "\n",
    "with open(ALL_IMPATHS, 'r') as f:\n",
    "    img_names = f.readlines()[PART_START:PART_END]\n",
    "\n",
    "for i in range(len(img_names)):\n",
    "    img_names[i] = img_names[i].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b844006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/jovyan/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dea3fe59c0a44599cd4230a35971222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ec20ed84d74ab5b04dd333f8db57fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/test_gen/lib/python3.7/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ca50d25d08415b982214fb8c7273ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e1fa7a4714cc3b69b6e1c43f660a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38064829508463544\n"
     ]
    }
   ],
   "source": [
    "#load images\n",
    "imgs = []\n",
    "for i in tqdm(range(len(img_names))):\n",
    "    name = img_names[i]\n",
    "    img = np.array(Image.open(name))\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.tile(img, (3, 1, 1))\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "    elif img.shape[2] > 3:\n",
    "        img = img[:, :, :3]\n",
    "    assert len(img.shape) == 3\n",
    "    assert img.shape[2] == 3\n",
    "    imgs.append(img)\n",
    "\n",
    "names = [clean_impath(path) for path in img_names]\n",
    "\n",
    "#load depths\n",
    "depths = []\n",
    "for i in tqdm(range(len(imgs))):\n",
    "    depths.append({'dep' : get_depth(np.array(imgs[i]))})\n",
    "\n",
    "#save depths\n",
    "for name, dep in zip(names, depths):\n",
    "    sio.savemat(f'{SAVE_PATH}/dep_in/{name}.mat', dep)\n",
    "\n",
    "depths = []\n",
    "gc.collect()\n",
    "\n",
    "#segs\n",
    "# # %%time\n",
    "ucms = [] \n",
    "for i in tqdm(range(len(imgs))):\n",
    "    ucms.append(ucm_model.get_hierarchy(imgs[i]))\n",
    "ucms = [filter_ucm(ucm, quantile=0.72) for ucm in ucms]\n",
    "gc.collect()\n",
    "\n",
    "segs = [get_mask(ucm, verbose=False) for ucm in ucms]\n",
    "#save segs\n",
    "for name, seg in zip(names, segs):\n",
    "    sio.savemat(f'{SAVE_PATH}/seg_in/{name}.mat', seg)\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7f213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_gen",
   "language": "python",
   "name": "test_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
